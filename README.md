# checkCompliance - Responsible Guidelines for Authorship Attribution Approaches in NLP

# ResponsibleAA: Responsible Guidelines for Authorship Attribution Approaches in NLP
Abstract: Authorship Attribution (AA) approaches in Natural Language Processing (NLP) are important in various domains.
However, they pose ethical, legal, and societal (ELS) challenges that remain under-explored within the legal and
NLP community. Our research presents a comprehensive framework of responsible guidelines for researchers and
stakeholders (designers, developers, testers, and end-users), encompassing the three phases of the AA life cycle:
design, development, and deployment. The framework comprises four key principles: privacy and data protection,
transparency and fairness, discrimination and unintended biases, and societal impact. It allows stakeholders to
identify potential issues and to weigh the benefits of AA research against privacy, transparency, discrimination, and
bias in AA applications, thereby mitigating potential risks and harm for the greater good of society. These guidelines
enable researchers and practitioners to justify their decisions and assist ethical committees in promoting responsible
practices and identifying ethical concerns related to NLP-based AA approaches, ultimately ensuring the responsible
development and deployment of AA tools for the benefit of society.

In this GitHub repository, we provide Python code designed to automatically assess compliance with our established guidelines across a sample of 67 authorship attribution studies. The purpose is to verify adherence to the suggested guidelines within this specific set of studies.
